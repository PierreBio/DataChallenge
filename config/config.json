{
    "logistic_regression": {
      "max_iter": 5000,
      "random_state": 0
    },
    "neural_network": {
      "input_shape": 768,
      "output_units": 28,
      "layers": [
        {"units": 512, "activation": "leaky_relu", "dropout": 0.3},
        {"units": 256, "activation": "leaky_relu", "dropout": 0.3},
        {"units": 128, "activation": "leaky_relu"}
      ],
      "output_activation": "softmax",
      "optimizer": "adam",
      "learning_rate": 0.0001,
      "loss": "categorical_crossentropy",
      "metrics": ["accuracy"],
      "epochs": 15,
      "batch_size": 32
    },
    "svm": {
      "kernel": "rbf",
      "C": 10,
      "gamma": 1
    },
    "naive_bayes": {
      "type": "GaussianNB"
    },
    "gradient_boosting": {
      "n_estimators": 5,
      "learning_rate": 0.001,
      "max_depth": 1,
      "random_state": 42
    }
  }
